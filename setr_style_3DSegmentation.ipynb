{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0+e4ZIcL37k1wd005oru3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1cZB3t2qDXh",
        "outputId": "5358fdd1-9218-4b7d-ce84-5d3cc67567ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vit-pytorch in /usr/local/lib/python3.12/dist-packages (1.11.7)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->vit-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->vit-pytorch) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->vit-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->vit-pytorch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install vit-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from vit_pytorch.simple_vit_3d import SimpleViT\n",
        "from vit_pytorch.simple_vit_3d import posemb_sincos_3d\n",
        "from einops import rearrange\n"
      ],
      "metadata": {
        "id": "jaoYynsYsZs0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_3d = SimpleViT(\n",
        "    image_size = 128,          # image size\n",
        "    frames = 16,               # number of frames\n",
        "    image_patch_size = 16,     # image patch size\n",
        "    frame_patch_size = 2,      # frame patch size\n",
        "    num_classes = 1000,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048\n",
        ")\n",
        "\n",
        "#example input:\n",
        "#video = torch.randn(4, 3, 16, 128, 128) # (batch, channels, frames, height, width)\n",
        "\n",
        "#embedding size will be (4, 1000)\n",
        "#preds = vit_3d(video) # (4, 1000)"
      ],
      "metadata": {
        "id": "vMXDksyerLwT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleDeconv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes):\n",
        "        super().__init__()\n",
        "        self.block = nn.ConvTranspose3d(in_planes, out_planes, kernel_size=2, stride=2, padding=0, output_padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class SingleConv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size):\n",
        "        super().__init__()\n",
        "        self.block = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=1,\n",
        "                               padding=((kernel_size - 1) // 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class Conv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            SingleConv3DBlock(in_planes, out_planes, kernel_size),\n",
        "            nn.BatchNorm3d(out_planes),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class Deconv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            SingleDeconv3DBlock(in_planes, out_planes),\n",
        "            SingleConv3DBlock(out_planes, out_planes, kernel_size),\n",
        "            nn.BatchNorm3d(out_planes),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ],
      "metadata": {
        "id": "bqBvmozAsuy5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleViT3dSeg(SimpleViT):\n",
        "  #add decoder attributes for segmentation\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "\n",
        "    print(kwargs['dim'], kwargs['num_classes'])\n",
        "    #upsampling decoder, from patch size 8x8x8 to 128x128x128\n",
        "    self.decoder = nn.Sequential(\n",
        "      Deconv3DBlock(kwargs['dim'], 256),\n",
        "      Deconv3DBlock(256, 128),\n",
        "      Deconv3DBlock(128, 64),\n",
        "      nn.Conv3d(in_channels=64, out_channels=kwargs['num_classes'], kernel_size=1)\n",
        "    )\n",
        "\n",
        "  #override the forward function so it doesn't apply the linear classification head\n",
        "  def forward(self, video):\n",
        "        *_, h, w, dtype = *video.shape, video.dtype\n",
        "\n",
        "        x = self.to_patch_embedding(video)\n",
        "        print(f\"patch shape: {x.shape}\")\n",
        "        _, depth_patch_size, height_patch_size, width_patch_size, _ = x.shape\n",
        "\n",
        "        pe = posemb_sincos_3d(x)\n",
        "        x = rearrange(x, 'b ... d -> b (...) d') + pe\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        print(f\"raw embeddings shape: {x.shape}\")\n",
        "        batch_size, patch_volume, embd_size = x.shape\n",
        "\n",
        "        #convert to per-patch embedding format for segmentation\n",
        "        #credit: code for re-arranging to per-patch format generated from chatgpt\n",
        "        feat_grid_embeddings = x.transpose(1, 2).contiguous().view(batch_size, embd_size, depth_patch_size, height_patch_size, width_patch_size)\n",
        "        print(f\"per-patch embedding dim: {feat_grid_embeddings.shape}\")\n",
        "\n",
        "        #x = x.mean(dim = 1) #don't apply pooling since we want the per-patch embedding\n",
        "        feat_grid_embeddings = self.to_latent(feat_grid_embeddings) #this is a palce holder, does nothing so we can keep it\n",
        "\n",
        "        logits = self.decoder(feat_grid_embeddings)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "raIJ8Zr5rshl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_3d_seg = SimpleViT3dSeg(\n",
        "    image_size = 64,          # image size\n",
        "    frames = 64,               # for volumetric data: this is slice number/depth\n",
        "    image_patch_size = 8,     # image patch size\n",
        "    frame_patch_size = 8,      # for volumetric data: this should be same as image patch size\n",
        "    num_classes = 3,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048,\n",
        ")\n",
        "\n",
        "test_input = torch.randn(1, 3, 64, 64, 64)\n",
        "\n",
        "preds = vit_3d_seg(test_input)\n",
        "\n",
        "print(preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHtpFeiJy1r9",
        "outputId": "3aad0291-5cba-4934-e158-92ff530b2809"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 3\n",
            "patch shape: torch.Size([1, 8, 8, 8, 1024])\n",
            "raw embeddings shape: torch.Size([1, 512, 1024])\n",
            "per-patch embedding dim: torch.Size([1, 1024, 8, 8, 8])\n",
            "torch.Size([1, 3, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9uDVIbVz6qa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}