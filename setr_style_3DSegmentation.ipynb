{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdyOMfDQaOh5+ZJFBm5fN8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1cZB3t2qDXh",
        "outputId": "b5f6a388-d5d0-4cd4-eb36-b47527564dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit-pytorch\n",
            "  Downloading vit_pytorch-1.11.7-py3-none-any.whl.metadata (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->vit-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->vit-pytorch) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->vit-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->vit-pytorch) (3.0.2)\n",
            "Downloading vit_pytorch-1.11.7-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vit-pytorch\n",
            "Successfully installed vit-pytorch-1.11.7\n"
          ]
        }
      ],
      "source": [
        "! pip install vit-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from vit_pytorch.simple_vit_3d import SimpleViT\n",
        "from vit_pytorch.simple_vit_3d import posemb_sincos_3d\n",
        "from einops import rearrange\n"
      ],
      "metadata": {
        "id": "jaoYynsYsZs0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_3d = SimpleViT(\n",
        "    image_size = 128,          # image size\n",
        "    frames = 16,               # number of frames\n",
        "    image_patch_size = 16,     # image patch size\n",
        "    frame_patch_size = 2,      # frame patch size\n",
        "    num_classes = 1000,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048\n",
        ")\n",
        "\n",
        "#example input:\n",
        "#video = torch.randn(4, 3, 16, 128, 128) # (batch, channels, frames, height, width)\n",
        "\n",
        "#embedding size will be (4, 1000)\n",
        "#preds = vit_3d(video) # (4, 1000)"
      ],
      "metadata": {
        "id": "vMXDksyerLwT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleViT3dSeg(SimpleViT):\n",
        "  #override the forward function so it doesn't apply the linear classification head\n",
        "  def forward(self, video):\n",
        "        *_, h, w, dtype = *video.shape, video.dtype\n",
        "\n",
        "        x = self.to_patch_embedding(video)\n",
        "        print(f\"patch shape: {x.shape}\")\n",
        "        _, depth_patch_size, height_patch_size, width_patch_size, _ = x.shape\n",
        "\n",
        "        pe = posemb_sincos_3d(x)\n",
        "        x = rearrange(x, 'b ... d -> b (...) d') + pe\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        print(f\"raw embeddings shape: {x.shape}\")\n",
        "        batch_size, patch_volume, embd_size = x.shape\n",
        "\n",
        "        #convert to per-patch embedding format for segmentation\n",
        "        #credit: code for re-arranging to per-patch format generated from chatgpt\n",
        "        feat_grid = x.transpose(1, 2).contiguous().view(batch_size, embd_size, depth_patch_size, height_patch_size, width_patch_size)\n",
        "        print(f\"per-patch embedding dim: {feat_grid.shape}\")\n",
        "\n",
        "        #x = x.mean(dim = 1) #don't apply pooling since we want the per-patch embedding\n",
        "        x = self.to_latent(x) #this is a palce holder, does nothing so we can keep it\n",
        "\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "raIJ8Zr5rshl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_3d_seg = SimpleViT3dSeg(\n",
        "    image_size = 128,          # image size\n",
        "    frames = 128,               # for volumetric data: this is slice number/depth\n",
        "    image_patch_size = 16,     # image patch size\n",
        "    frame_patch_size = 16,      # for volumetric data: this should be same as image patch size\n",
        "    num_classes = 1000,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048\n",
        ")\n",
        "\n",
        "video = torch.randn(4, 3, 128, 128, 128)\n",
        "\n",
        "preds = vit_3d_seg(video)\n",
        "\n",
        "print(preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHtpFeiJy1r9",
        "outputId": "f845fbd2-038a-436c-9233-844317b5a437"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patch shape: torch.Size([4, 8, 8, 8, 1024])\n",
            "raw embeddings shape: torch.Size([4, 512, 1024])\n",
            "per-patch embedding dim: torch.Size([4, 1024, 8, 8, 8])\n",
            "torch.Size([4, 512, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9uDVIbVz6qa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}