{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMv8KbWhWfrZFm7iuK/lyo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1cZB3t2qDXh",
        "outputId": "ab79b753-f9b3-4748-b736-e2c0be40d3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit-pytorch\n",
            "  Downloading vit_pytorch-1.11.7-py3-none-any.whl.metadata (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from vit-pytorch) (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->vit-pytorch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->vit-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->vit-pytorch) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->vit-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->vit-pytorch) (3.0.2)\n",
            "Downloading vit_pytorch-1.11.7-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vit-pytorch\n",
            "Successfully installed vit-pytorch-1.11.7\n"
          ]
        }
      ],
      "source": [
        "! pip install vit-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from vit_pytorch.simple_vit_3d import SimpleViT\n",
        "from vit_pytorch.simple_vit_3d import posemb_sincos_3d\n",
        "from einops import rearrange\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import glob\n",
        "import time"
      ],
      "metadata": {
        "id": "jaoYynsYsZs0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_3d = SimpleViT(\n",
        "    image_size = 128,          # image size\n",
        "    frames = 16,               # number of frames\n",
        "    image_patch_size = 16,     # image patch size\n",
        "    frame_patch_size = 2,      # frame patch size\n",
        "    num_classes = 1000,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048\n",
        ")\n",
        "\n",
        "#example input:\n",
        "#video = torch.randn(4, 3, 16, 128, 128) # (batch, channels, frames, height, width)\n",
        "\n",
        "#embedding size will be (4, 1000)\n",
        "#preds = vit_3d(video) # (4, 1000)"
      ],
      "metadata": {
        "id": "vMXDksyerLwT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#source code for these conv block implemenations is from this UNETR implementation: https://github.com/tamasino52/UNETR/blob/main/unetr.py#L231\n",
        "class SingleDeconv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes):\n",
        "        super().__init__()\n",
        "        self.block = nn.ConvTranspose3d(in_planes, out_planes, kernel_size=2, stride=2, padding=0, output_padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class SingleConv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size):\n",
        "        super().__init__()\n",
        "        self.block = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=1,\n",
        "                               padding=((kernel_size - 1) // 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class Conv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            SingleConv3DBlock(in_planes, out_planes, kernel_size),\n",
        "            nn.BatchNorm3d(out_planes),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class Deconv3DBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            SingleDeconv3DBlock(in_planes, out_planes),\n",
        "            SingleConv3DBlock(out_planes, out_planes, kernel_size),\n",
        "            nn.BatchNorm3d(out_planes),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ],
      "metadata": {
        "id": "bqBvmozAsuy5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleViT3dSeg(SimpleViT):\n",
        "  #add decoder attributes for segmentation\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "\n",
        "    print(kwargs['dim'], kwargs['num_classes'])\n",
        "    #upsampling decoder, from patch size 8x8x8 to 128x128x128\n",
        "    self.decoder = nn.Sequential(\n",
        "      Deconv3DBlock(kwargs['dim'], 256),\n",
        "      Deconv3DBlock(256, 128),\n",
        "      Deconv3DBlock(128, 64),\n",
        "      nn.Conv3d(in_channels=64, out_channels=kwargs['num_classes'], kernel_size=1)\n",
        "    )\n",
        "\n",
        "  #override the forward function so embeddings get fed into decoder instead of linear classification head\n",
        "  def forward(self, video):\n",
        "        *_, h, w, dtype = *video.shape, video.dtype\n",
        "\n",
        "        x = self.to_patch_embedding(video)\n",
        "        #print(f\"patch shape: {x.shape}\")\n",
        "        _, depth_patch_size, height_patch_size, width_patch_size, _ = x.shape\n",
        "\n",
        "        pe = posemb_sincos_3d(x)\n",
        "        x = rearrange(x, 'b ... d -> b (...) d') + pe\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        #print(f\"raw embeddings shape: {x.shape}\")\n",
        "        batch_size, patch_volume, embd_size = x.shape\n",
        "\n",
        "        #convert to per-patch embedding format for segmentation\n",
        "        #credit: code for re-arranging to per-patch format generated from chatgpt\n",
        "        feat_grid_embeddings = x.transpose(1, 2).contiguous().view(batch_size, embd_size, depth_patch_size, height_patch_size, width_patch_size)\n",
        "        #print(f\"per-patch embedding dim: {feat_grid_embeddings.shape}\")\n",
        "\n",
        "        #x = x.mean(dim = 1) #don't apply pooling since we want the per-patch embedding\n",
        "        feat_grid_embeddings = self.to_latent(feat_grid_embeddings) #this is a palce holder, does nothing so we can keep it\n",
        "\n",
        "        logits = self.decoder(feat_grid_embeddings)\n",
        "        return logits\n",
        "\n",
        "  def logits_to_mask(self, logits):\n",
        "    return logits.argmax(dim=1)"
      ],
      "metadata": {
        "id": "raIJ8Zr5rshl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_vit_seg_model = SimpleViT3dSeg(\n",
        "    image_size = 64,          # image size\n",
        "    frames = 64,               # for volumetric data: this is slice number/depth\n",
        "    image_patch_size = 8,     # image patch size\n",
        "    frame_patch_size = 8,      # for volumetric data: this should be same as image patch size\n",
        "    num_classes = 3,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048,\n",
        ")\n",
        "\n",
        "test_input = torch.randn(1, 3, 64, 64, 64)\n",
        "\n",
        "preds = test_vit_seg_model(test_input)\n",
        "\n",
        "print(preds.shape, type(preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHtpFeiJy1r9",
        "outputId": "a71edb54-48c1-4eee-dd9d-15dea0acc235"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 3\n",
            "torch.Size([1, 3, 64, 64, 64]) <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chatgpt generated using prompt \"generate a simple function that generates a 3 channel white cube, inside it is a red sphere of varied position and radius\"\n",
        "\n",
        "def make_rgb_cube_with_red_sphere(T=64, H=64, W=64, cube_margin=8,\n",
        "                                  min_radius=4, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      img:  (3, T, H, W) float32 in [0,1]\n",
        "      mask: (T, H, W)    long: 0=bg, 1=cube, 2=sphere\n",
        "    \"\"\"\n",
        "    # --- init ---\n",
        "    img  = torch.zeros(3, T, H, W, dtype=torch.float32, device=device)  # RGB\n",
        "    mask = torch.zeros(T, H, W, dtype=torch.long, device=device)        # seg labels\n",
        "\n",
        "    # --- define cube bounds (axis-aligned) ---\n",
        "    z0, z1 = cube_margin, T - cube_margin\n",
        "    y0, y1 = cube_margin, H - cube_margin\n",
        "    x0, x1 = cube_margin, W - cube_margin\n",
        "\n",
        "    # white cube\n",
        "    img[:, z0:z1, y0:y1, x0:x1] = 1.0\n",
        "    mask[  z0:z1, y0:y1, x0:x1] = 1\n",
        "\n",
        "    # --- random sphere INSIDE the cube ---\n",
        "    # max radius so sphere fits fully inside cube\n",
        "    max_r = min((z1 - z0), (y1 - y0), (x1 - x0)) // 3\n",
        "    r = int(torch.randint(min_radius, max( min_radius+1, max_r+1 ), ()).item())\n",
        "\n",
        "    cz = int(torch.randint(z0 + r, z1 - r, ()).item())\n",
        "    cy = int(torch.randint(y0 + r, y1 - r, ()).item())\n",
        "    cx = int(torch.randint(x0 + r, x1 - r, ()).item())\n",
        "\n",
        "    # build sphere mask\n",
        "    zz = torch.arange(T, device=device).view(T, 1, 1)\n",
        "    yy = torch.arange(H, device=device).view(1, H, 1)\n",
        "    xx = torch.arange(W, device=device).view(1, 1, W)\n",
        "    sphere = (zz - cz)**2 + (yy - cy)**2 + (xx - cx)**2 <= r**2\n",
        "\n",
        "    # paint sphere: red on top of cube\n",
        "    img[0][sphere] = 1.0   # R\n",
        "    img[1][sphere] = 0.0   # G\n",
        "    img[2][sphere] = 0.0   # B\n",
        "    mask[sphere]    = 2\n",
        "\n",
        "    return img.contiguous(), mask.contiguous()\n",
        "\n",
        "\n",
        "\n",
        "###chatgpt generated using prompt \"generate a function to visualize the generated data and mask\"\n",
        "\n",
        "# tiny palette for mask coloring: 0..5\n",
        "_PALETTE = np.array([\n",
        "    [0,   0,   0],   # 0 bg\n",
        "    [255, 0,   0],   # 1 red\n",
        "    [0,   255, 0],   # 2 green\n",
        "    [0,   0,   255], # 3 blue\n",
        "    [255, 255, 0],   # 4 yellow\n",
        "    [255, 0,   255], # 5 magenta\n",
        "], dtype=np.uint8)\n",
        "\n",
        "\n",
        "def save_gif(vol, path=\"volume.gif\", duration=100, loop=0):\n",
        "    \"\"\"\n",
        "    vol:\n",
        "      - image RGB: (3, T, H, W), float in [0,1]\n",
        "      - mask:       (T, H, W),   int (class ids)\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "\n",
        "    # --- mask case: (T,H,W) ints ---\n",
        "    if vol.ndim == 3 and vol.dtype in (torch.long, torch.int64, torch.int32):\n",
        "        T, H, W = vol.shape\n",
        "        m = vol.detach().cpu().numpy().astype(np.int64)\n",
        "        m = np.clip(m, 0, _PALETTE.shape[0]-1)\n",
        "        rgb = _PALETTE[m]  # (T,H,W,3)\n",
        "        for i in range(T):\n",
        "            frames.append(Image.fromarray(rgb[i], mode=\"RGB\"))\n",
        "\n",
        "    # --- image case: (3,T,H,W) floats ---\n",
        "    elif vol.ndim == 4 and vol.shape[0] == 3:\n",
        "        _, T, _, _ = vol.shape\n",
        "        v = vol.detach().cpu().clamp(0, 1)\n",
        "        for i in range(T):\n",
        "            slice_rgb = (v[:, i].permute(1, 2, 0).numpy() * 255).astype(\"uint8\")\n",
        "            frames.append(Image.fromarray(slice_rgb, mode=\"RGB\"))\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported shape/dtype for save_gif: {tuple(vol.shape)}, {vol.dtype}\")\n",
        "\n",
        "    frames[0].save(path, save_all=True, append_images=frames[1:], duration=duration, loop=loop)\n",
        "###"
      ],
      "metadata": {
        "id": "AL4qQdBf8aaG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate dataset\n",
        "train_img = []\n",
        "train_mask = []\n",
        "test_img = []\n",
        "test_mask = []\n",
        "for i in range(100):\n",
        "  img, mask = make_rgb_cube_with_red_sphere(device=\"cuda\")\n",
        "  train_img.append(img)\n",
        "  train_mask.append(mask)\n",
        "\n",
        "for i in range(30):\n",
        "  img, mask = make_rgb_cube_with_red_sphere(device=\"cuda\")\n",
        "  test_img.append(img)\n",
        "  test_mask.append(mask)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(torch.stack(train_img), torch.stack(train_mask)), batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(torch.stack(test_img), torch.stack(test_mask)), batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "IiaPUJ-g_Rto"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, mask = make_rgb_cube_with_red_sphere(device=\"cuda\")\n",
        "save_gif(img, \"volume.gif\")\n",
        "save_gif(mask, \"mask.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihnsH0UgA9ER",
        "outputId": "971fd8bd-87f2-4867-e7c5-3a5375238b85"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3545402226.py:84: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  frames.append(Image.fromarray(slice_rgb, mode=\"RGB\"))\n",
            "/tmp/ipython-input-3545402226.py:76: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  frames.append(Image.fromarray(rgb[i], mode=\"RGB\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "vit_3d_seg = SimpleViT3dSeg(\n",
        "    image_size = 64,\n",
        "    frames = 64,\n",
        "    image_patch_size = 8,\n",
        "    frame_patch_size = 8,\n",
        "    num_classes = 3,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 100\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "vit_3d_seg.to(device)\n",
        "optimizer = optim.Adam(vit_3d_seg.parameters(), lr=1e-3, weight_decay=1e-2)\n",
        "train_loss_list, test_loss_list = [], []\n",
        "\n",
        "best_test_loss = float('inf')\n",
        "early_stop_patience = 15\n",
        "early_stop_counter = 0\n",
        "total_elapsed_time = 0\n",
        "\n",
        "for ep in range(epochs):\n",
        "  vit_3d_seg.train()\n",
        "  train_loss = 0.0\n",
        "  ep_start_time = time.perf_counter()\n",
        "\n",
        "  for x, y in train_loader:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    logits = vit_3d_seg(x)\n",
        "    loss = ce_loss(logits, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "  train_loss = train_loss / len(train_loader)\n",
        "\n",
        "  #eval\n",
        "  vit_3d_seg.eval()\n",
        "  test_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      logits = vit_3d_seg(x)\n",
        "      loss = ce_loss(logits, y)\n",
        "      test_loss += loss.item()\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "\n",
        "  if test_loss < best_test_loss:\n",
        "    best_test_loss = test_loss\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    past_weights = glob.glob(f\"{vit_3d_seg.__class__.__name__}_best*\")\n",
        "    for file in past_weights:\n",
        "      os.remove(file)\n",
        "\n",
        "    torch.save(vit_3d_seg.state_dict(), f\"{vit_3d_seg.__class__.__name__}_best_{ep}ep.pth\")\n",
        "  else:\n",
        "    early_stop_counter += 1\n",
        "    if early_stop_counter >= early_stop_patience:\n",
        "      print(f\"Early stopping at epoch {ep}\")\n",
        "      break\n",
        "\n",
        "  train_loss_list.append(train_loss)\n",
        "  test_loss_list.append(test_loss)\n",
        "  ep_end_time = time.perf_counter()\n",
        "  ep_elapsed_time = ep_end_time - ep_start_time\n",
        "  total_elapsed_time += ep_elapsed_time\n",
        "  print(f\"epoch: {ep}, train loss: {train_loss:.4f}, test loss: {test_loss:.4f}, elapsed time: {ep_elapsed_time}\")\n",
        "\n",
        "\n",
        "print(f\"Total training time: {total_elapsed_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9uDVIbVz6qa",
        "outputId": "ef769401-feee-479b-89f0-469d92961568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 3\n",
            "epoch: 0, train loss: 0.5545, test loss: 7.3761, elapsed time: 16.477347907000876\n",
            "epoch: 1, train loss: 0.3011, test loss: 1.2107, elapsed time: 16.884732521999467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot train val loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss, label='train loss')\n",
        "plt.plot(test_loss, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "4_tF2qOkzG9t",
        "outputId": "573d2970-f5d6-4095-d983-343d6828f8fb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize some predictions\n",
        "for i in range(len(test_img)):\n",
        "  img, mask = test_img[i], test_mask[i]\n",
        "  img = img.unsqueeze(0).to(device)\n",
        "  mask = mask.unsqueeze(0).to(device)\n",
        "  logits = vit_3d_seg(img)\n",
        "  pred_mask = vit_3d_seg.logits_to_mask(logits)\n",
        "  save_gif(pred_mask, f\"pred_mask{i}.gif\")\n",
        "  save_gif(mask, f\"gt_mask{i}.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "I88HyoFMLfua",
        "outputId": "64c8b38a-57ae-4674-ef20-3b3a55b9b2a8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SimpleViT3dSeg' object has no attribute 'logits_to_mask'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2376527781.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_3d_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_3d_seg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0msave_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"pred_mask{i}.gif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0msave_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"gt_mask{i}.gif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1963\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SimpleViT3dSeg' object has no attribute 'logits_to_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZM7WRgNLa1sb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}